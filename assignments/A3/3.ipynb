{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9ec8df3",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73b1a1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blozerx/venvs/smai-env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/blozerx/venvs/smai-env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import wandb\n",
    "from sklearn.datasets import fetch_openml\n",
    "import glob\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, roc_curve\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from IPython import get_ipython\n",
    "get_ipython().kernel.do_one_iteration = lambda: None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab778c18",
   "metadata": {},
   "source": [
    "# Implement Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef1295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    \"\"\"ReLU activation function\"\"\"\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass: f(x) = max(0, x)\"\"\"\n",
    "        self.input = x\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"Backward pass: f'(x) = 1 if x > 0, else 0\"\"\"\n",
    "        return grad_output * (self.input > 0)\n",
    "\n",
    "class Tanh:\n",
    "    \"\"\"Tanh activation function\"\"\"\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass: f(x) = tanh(x)\"\"\"\n",
    "        self.output = np.tanh(x)\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"Backward pass: f'(x) = 1 - tanh²(x)\"\"\"\n",
    "        return grad_output * (1 - self.output ** 2)\n",
    "\n",
    "class Sigmoid:\n",
    "    \"\"\"Sigmoid activation function\"\"\"\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass: f(x) = 1 / (1 + exp(-x))\"\"\"\n",
    "        # Clip x to prevent overflow\n",
    "        x_clipped = np.clip(x, -500, 500)\n",
    "        self.output = 1 / (1 + np.exp(-x_clipped))\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"Backward pass: f'(x) = sigmoid(x) * (1 - sigmoid(x))\"\"\"\n",
    "        return grad_output * self.output * (1 - self.output)\n",
    "\n",
    "class Identity:\n",
    "    \"\"\"Identity activation function (no activation)\"\"\"\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass: f(x) = x\"\"\"\n",
    "        return x\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"Backward pass: f'(x) = 1\"\"\"\n",
    "        return grad_output\n",
    "\n",
    "\n",
    "class Linear:\n",
    "    \"\"\"Linear (fully connected) layer with optional activation function\"\"\"\n",
    "    \n",
    "    def __init__(self, input_width, output_width, activation=Identity()):\n",
    "        \"\"\"\n",
    "        Initialize linear layer\n",
    "        \"\"\"\n",
    "        self.input_width = input_width\n",
    "        self.output_width = output_width\n",
    "        self.activation = activation\n",
    "        \n",
    "        # Initialize weights and biases using Xavier/Glorot initialization\n",
    "        self.weights = np.random.randn(input_width, output_width) * np.sqrt(2.0 / input_width)\n",
    "        self.biases = np.zeros(output_width)\n",
    "        \n",
    "        # Initialize cumulative gradients\n",
    "        self.grad_weights = np.zeros_like(self.weights)\n",
    "        self.grad_biases = np.zeros_like(self.biases)\n",
    "        \n",
    "        # Store data for backward pass\n",
    "        self.input = None\n",
    "        self.linear_output = None\n",
    "        self.output = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the linear layer\n",
    "        \"\"\"\n",
    "        self.input = x\n",
    "        \n",
    "        # Linear transformation: y = xW + b\n",
    "        self.linear_output = np.dot(x, self.weights) + self.biases\n",
    "        \n",
    "        # Apply activation function\n",
    "        self.output = self.activation.forward(self.linear_output)\n",
    "        \n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        Backward pass through the linear layer\n",
    "        \"\"\"\n",
    "        # Gradient through activation function\n",
    "        grad_activation = self.activation.backward(grad_output)\n",
    "        \n",
    "        # Gradients with respect to weights and biases\n",
    "        if len(self.input.shape) == 1:\n",
    "            # Single sample\n",
    "            self.grad_weights += np.outer(self.input, grad_activation)\n",
    "            self.grad_biases += grad_activation\n",
    "        else:\n",
    "            # Batch of samples\n",
    "            self.grad_weights += np.dot(self.input.T, grad_activation)\n",
    "            self.grad_biases += np.sum(grad_activation, axis=0)\n",
    "        \n",
    "        # Gradient with respect to input\n",
    "        grad_input = np.dot(grad_activation, self.weights.T)\n",
    "        \n",
    "        return grad_input\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\"Reset accumulated gradients to zero\"\"\"\n",
    "        self.grad_weights.fill(0)\n",
    "        self.grad_biases.fill(0)\n",
    "    \n",
    "    def update(self, learning_rate):\n",
    "        \"\"\"Update parameters using accumulated gradients\"\"\"\n",
    "        self.weights -= learning_rate * self.grad_weights\n",
    "        self.biases -= learning_rate * self.grad_biases\n",
    "\n",
    "\n",
    "class MSELoss:\n",
    "    \"\"\"Mean Squared Error loss function\"\"\"\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Compute MSE loss\n",
    "        \"\"\"\n",
    "        self.y_pred = y_pred\n",
    "        self.y_true = y_true\n",
    "        \n",
    "        # MSE = (1/n) * sum((y_pred - y_true)^2)\n",
    "        loss = np.mean((y_pred - y_true) ** 2)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Compute gradient of MSE loss\n",
    "        \"\"\"\n",
    "        # d(MSE)/dy_pred = 2 * (y_pred - y_true) / n\n",
    "        n = len(self.y_pred) if len(self.y_pred.shape) > 0 else 1\n",
    "        return 2 * (self.y_pred - self.y_true) / n\n",
    "\n",
    "class BCELoss:\n",
    "    \"\"\"Binary Cross Entropy loss function\"\"\"\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Compute BCE loss\n",
    "        \"\"\"\n",
    "        self.y_pred = y_pred\n",
    "        self.y_true = y_true\n",
    "        \n",
    "        # Clip predictions to prevent log(0)\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "        self.y_pred_clipped = y_pred_clipped\n",
    "        \n",
    "        # BCE = -mean(y_true * log(y_pred) + (1 - y_true) * log(1 - y_pred))\n",
    "        loss = -np.mean(y_true * np.log(y_pred_clipped) + (1 - y_true) * np.log(1 - y_pred_clipped))\n",
    "        return loss\n",
    "    \n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Compute gradient of BCE loss\n",
    "        \"\"\"\n",
    "        # d(BCE)/dy_pred = -(y_true / y_pred - (1 - y_true) / (1 - y_pred)) / n\n",
    "        n = len(self.y_pred) if len(self.y_pred.shape) > 0 else 1\n",
    "        grad = -(self.y_true / self.y_pred_clipped - (1 - self.y_true) / (1 - self.y_pred_clipped)) / n\n",
    "        return grad\n",
    "\n",
    "\n",
    "class Model:\n",
    "    \"\"\"Neural network model class\"\"\"\n",
    "    \n",
    "    def __init__(self, layers, loss_fn, learning_rate=0.001):\n",
    "        \"\"\"\n",
    "        Initialize model\n",
    "        \"\"\"\n",
    "        self.layers = layers\n",
    "        self.loss_fn = loss_fn\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Training metrics\n",
    "        self.train_losses = []\n",
    "        self.samples_seen = []\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through all layers\n",
    "        \"\"\"\n",
    "        output = x\n",
    "        for layer in self.layers:\n",
    "            output = layer.forward(output)\n",
    "        return output\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        Backward pass through all layers\n",
    "        \"\"\"\n",
    "        grad = grad_output\n",
    "        for layer in reversed(self.layers):\n",
    "            grad = layer.backward(grad)\n",
    "        return grad\n",
    "    \n",
    "    def train(self, x, y):\n",
    "        \"\"\"\n",
    "        Perform forward pass, compute loss, and backpropagate\n",
    "        \"\"\"\n",
    "        # Forward pass\n",
    "        y_pred = self.forward(x)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = self.loss_fn.forward(y_pred, y)\n",
    "        \n",
    "        # Backward pass\n",
    "        grad_loss = self.loss_fn.backward()\n",
    "        self.backward(grad_loss)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\"Reset gradients in all layers\"\"\"\n",
    "        for layer in self.layers:\n",
    "            layer.zero_grad()\n",
    "    \n",
    "    def update(self):\n",
    "        \"\"\"Update parameters and reset gradients\"\"\"\n",
    "        for layer in self.layers:\n",
    "            layer.update(self.learning_rate)\n",
    "        self.zero_grad()\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Make predictions without gradient computation\n",
    "        \"\"\"\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def save_to(self, path):\n",
    "        \"\"\"\n",
    "        Save model parameters to file\n",
    "        \"\"\"\n",
    "        params = {}\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            params[f'layer_{i}_weights'] = layer.weights\n",
    "            params[f'layer_{i}_biases'] = layer.biases\n",
    "        \n",
    "        np.savez(path, **params)\n",
    "        print(f\"Model saved to {path}\")\n",
    "    \n",
    "    def load_from(self, path):\n",
    "        \"\"\"\n",
    "        Load model parameters from file\n",
    "        \"\"\"\n",
    "        try:\n",
    "            params = np.load(path)\n",
    "            \n",
    "            # Check if architecture matches\n",
    "            for i, layer in enumerate(self.layers):\n",
    "                weight_key = f'layer_{i}_weights'\n",
    "                bias_key = f'layer_{i}_biases'\n",
    "                \n",
    "                if weight_key not in params or bias_key not in params:\n",
    "                    raise ValueError(f\"Missing parameters for layer {i}\")\n",
    "                \n",
    "                saved_weights = params[weight_key]\n",
    "                saved_biases = params[bias_key]\n",
    "                \n",
    "                if saved_weights.shape != layer.weights.shape:\n",
    "                    raise ValueError(f\"Weight shape mismatch for layer {i}: \"\n",
    "                                   f\"expected {layer.weights.shape}, got {saved_weights.shape}\")\n",
    "                \n",
    "                if saved_biases.shape != layer.biases.shape:\n",
    "                    raise ValueError(f\"Bias shape mismatch for layer {i}: \"\n",
    "                                   f\"expected {layer.biases.shape}, got {saved_biases.shape}\")\n",
    "                \n",
    "                # Load parameters\n",
    "                layer.weights = saved_weights.copy()\n",
    "                layer.biases = saved_biases.copy()\n",
    "            \n",
    "            print(f\"Model loaded from {path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error loading model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05b9075",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba43f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataset, epochs=100, batch_size=32, grad_accumulation_steps=1, \n",
    "                patience=10, relative_loss_threshold=0.01):\n",
    "    \"\"\"\n",
    "    Train the model with early stopping\n",
    "    \"\"\"\n",
    "    # Create data loader\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Training history\n",
    "    train_losses = []\n",
    "    epoch_losses = []\n",
    "    samples_seen = []\n",
    "    sample_count = 0\n",
    "    \n",
    "    print(f\"Starting training...\")\n",
    "    print(f\"Model: {len(model.layers)} layers\")\n",
    "    print(f\"Dataset size: {len(dataset)}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    print(f\"Gradient accumulation steps: {grad_accumulation_steps}\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        epoch_samples = 0\n",
    "\n",
    "        for batch_idx, (coords_batch, labels_batch) in enumerate(dataloader):\n",
    "            # Convert to numpy arrays\n",
    "            x = coords_batch.numpy()\n",
    "            y = labels_batch.numpy() # Reshape for proper broadcasting\n",
    "            # Train on batch\n",
    "            loss = model.train(x, y)\n",
    "            \n",
    "            # Accumulate metrics\n",
    "            epoch_loss += loss * len(x)\n",
    "            epoch_samples += len(x)\n",
    "            sample_count += len(x)\n",
    "            \n",
    "            # Store loss and sample count for each batch\n",
    "            train_losses.append(loss)\n",
    "            samples_seen.append(sample_count)\n",
    "            \n",
    "\n",
    "            model.update()\n",
    "        # Calculate average epoch loss\n",
    "        avg_epoch_loss = epoch_loss / epoch_samples\n",
    "        epoch_losses.append(avg_epoch_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_epoch_loss:.6f}\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if epoch >= patience:\n",
    "            old_loss = epoch_losses[epoch - patience]\n",
    "            current_loss = avg_epoch_loss\n",
    "            \n",
    "            # Check if loss improved by at least the threshold\n",
    "            if current_loss >= (1- relative_loss_threshold) * old_loss:\n",
    "                print(f\"Early stopping triggered! Loss did not improve by {relative_loss_threshold*100}% \"\n",
    "                          f\"over the last {patience} epochs.\")\n",
    "                break\n",
    "    \n",
    "    # Save training results\n",
    "    history = {\n",
    "        'train_losses': train_losses,\n",
    "        'epoch_losses': epoch_losses,\n",
    "        'samples_seen': samples_seen,\n",
    "        'final_loss': epoch_losses[-1],\n",
    "        'epochs_trained': len(epoch_losses)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nTraining completed!\")\n",
    "    print(f\"Final loss: {epoch_losses[-1]:.6f}\")\n",
    "    print(f\"Epochs trained: {len(epoch_losses)}\")\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%H%M%S\")\n",
    "    run_dir = os.path.join(\"runs\", f\"run_{timestamp}\")\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    model_path = os.path.join(run_dir, 'model.npz')\n",
    "    model.save_to(model_path)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(samples_seen, train_losses, alpha=0.7)\n",
    "    plt.xlabel('Samples Seen')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss vs Samples')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, len(epoch_losses) + 1), epoch_losses)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.title('Epoch Loss')\n",
    "    plt.grid(True)\n",
    "    plt.suptitle(\"(sudershan.sarraf)\", fontsize=16, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plot_path = os.path.join(run_dir, 'training_plot.png')\n",
    "    plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abd0824",
   "metadata": {},
   "source": [
    "# MLP Autoencoder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0621964",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPAutoencoder:\n",
    "    \"\"\"\n",
    "    Multi-Layer Perceptron Autoencoder using the existing MLP framework\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, encoder_hidden_dims, latent_dim, \n",
    "                 decoder_hidden_dims=None, activation_fn=ReLU, learning_rate=0.001):\n",
    "        \"\"\"\n",
    "        Initialize the MLPAutoencoder\n",
    "        \"\"\"\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # If decoder dimensions not specified, mirror the encoder (reversed)\n",
    "        if decoder_hidden_dims is None:\n",
    "            decoder_hidden_dims = encoder_hidden_dims[::-1]\n",
    "        \n",
    "        # Build encoder layers\n",
    "        encoder_layers = []\n",
    "        \n",
    "        # Input to first hidden layer\n",
    "        prev_dim = input_dim\n",
    "        for hidden_dim in encoder_hidden_dims:\n",
    "            encoder_layers.append(Linear(prev_dim, hidden_dim, activation_fn()))\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        # Last hidden layer to latent layer\n",
    "        encoder_layers.append(Linear(prev_dim, latent_dim, activation_fn()))\n",
    "        \n",
    "        # Build decoder layers\n",
    "        decoder_layers = []\n",
    "        \n",
    "        # Latent to first decoder hidden layer\n",
    "        prev_dim = latent_dim\n",
    "        for hidden_dim in decoder_hidden_dims:\n",
    "            decoder_layers.append(Linear(prev_dim, hidden_dim, activation_fn()))\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        # Last hidden layer to output (reconstruction)\n",
    "        # Use sigmoid activation for output to ensure values are in [0,1] range\n",
    "        decoder_layers.append(Linear(prev_dim, input_dim, Sigmoid()))\n",
    "        \n",
    "        # Create the complete autoencoder as a single model\n",
    "        all_layers = encoder_layers + decoder_layers\n",
    "        \n",
    "        # Create model with MSE loss (appropriate for reconstruction)\n",
    "        self.model = Model(all_layers, MSELoss(), learning_rate)\n",
    "        \n",
    "        # Store layer indices for encoder/decoder separation\n",
    "        self.encoder_layers = encoder_layers\n",
    "        self.decoder_layers = decoder_layers\n",
    "        self.num_encoder_layers = len(encoder_layers)\n",
    "        \n",
    "        print(f\"MLPAutoencoder created:\")\n",
    "        print(f\"  Input dimension: {input_dim}\")\n",
    "        print(f\"  Encoder architecture: {input_dim} -> {' -> '.join(map(str, encoder_hidden_dims))} -> {latent_dim}\")\n",
    "        print(f\"  Decoder architecture: {latent_dim} -> {' -> '.join(map(str, decoder_hidden_dims))} -> {input_dim}\")\n",
    "        print(f\"  Total parameters: {self.count_parameters()}\")\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        Encode input to latent representation\n",
    "        \"\"\"\n",
    "        # Forward pass through encoder layers only\n",
    "        output = x\n",
    "        for layer in self.encoder_layers:\n",
    "            output = layer.forward(output)\n",
    "        return output\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        Decode latent representation to reconstruction\n",
    "        \"\"\"\n",
    "        # Forward pass through decoder layers only\n",
    "        output = z\n",
    "        for layer in self.decoder_layers:\n",
    "            output = layer.forward(output)\n",
    "        return output\n",
    "    \n",
    "    def get_latent_representation(self, x):\n",
    "        \"\"\"\n",
    "        Get latent representation of input data\n",
    "        \"\"\"\n",
    "        return self.encode(x)\n",
    "    \n",
    "    def count_parameters(self):\n",
    "        \"\"\"\n",
    "        Count total number of parameters in the autoencoder\n",
    "        \"\"\"\n",
    "        total_params = 0\n",
    "        for layer in self.model.layers:\n",
    "            total_params += layer.weights.size + layer.biases.size\n",
    "        return total_params\n",
    "    \n",
    "    def analyze_latent_space(self, data, labels=None, num_samples=1000):\n",
    "        \"\"\"\n",
    "        Analyze the latent space representation\n",
    "        \n",
    "        Args:\n",
    "            data: Input data\n",
    "            labels: Labels for the data (optional)\n",
    "            num_samples (int): Number of samples to analyze\n",
    "        \"\"\"\n",
    "        # Sample data\n",
    "        if num_samples < len(data):\n",
    "            indices = np.random.choice(len(data), num_samples, replace=False)\n",
    "            sampled_data = [data[i] for i in indices]\n",
    "            if labels is not None:\n",
    "                sampled_labels = [labels[i] for i in indices]\n",
    "        else:\n",
    "            sampled_data = data\n",
    "            sampled_labels = labels\n",
    "        \n",
    "        # Get latent representations\n",
    "        latent_representations = []\n",
    "        for sample in sampled_data:\n",
    "            if isinstance(sample, (list, tuple)):\n",
    "                x = sample[0].numpy()\n",
    "            else:\n",
    "                x = sample.numpy()\n",
    "            \n",
    "            x_flat = x.reshape(1, -1)\n",
    "            latent = self.get_latent_representation(x_flat)\n",
    "            latent_representations.append(latent.flatten())\n",
    "        \n",
    "        latent_matrix = np.array(latent_representations)\n",
    "        \n",
    "        # Visualize latent space (if 2D or can be reduced to 2D)\n",
    "        if self.latent_dim == 2:\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            if sampled_labels is not None:\n",
    "                scatter = plt.scatter(latent_matrix[:, 0], latent_matrix[:, 1], \n",
    "                                    c=sampled_labels, cmap='tab10', alpha=0.7)\n",
    "                plt.colorbar(scatter)\n",
    "            else:\n",
    "                plt.scatter(latent_matrix[:, 0], latent_matrix[:, 1], alpha=0.7)\n",
    "            plt.xlabel('Latent Dimension 1')\n",
    "            plt.ylabel('Latent Dimension 2')\n",
    "            plt.title('2D Latent Space Visualization')\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "        else:\n",
    "            # Show statistics for higher dimensional latent spaces\n",
    "            print(f\"Latent space statistics (dimension: {self.latent_dim}):\")\n",
    "            print(f\"Mean: {np.mean(latent_matrix, axis=0)}\")\n",
    "            print(f\"Std: {np.std(latent_matrix, axis=0)}\")\n",
    "            print(f\"Min: {np.min(latent_matrix, axis=0)}\")\n",
    "            print(f\"Max: {np.max(latent_matrix, axis=0)}\")\n",
    "            \n",
    "            # Plot histogram of latent dimensions\n",
    "            fig, axes = plt.subplots(2, min(4, self.latent_dim//2 + 1), figsize=(12, 6))\n",
    "            axes = axes.flatten()\n",
    "            \n",
    "            for i in range(min(8, self.latent_dim)):\n",
    "                axes[i].hist(latent_matrix[:, i], bins=30, alpha=0.7)\n",
    "                axes[i].set_title(f'Latent Dim {i+1}')\n",
    "                axes[i].grid(True)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        return latent_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0154ac20",
   "metadata": {},
   "source": [
    "# Loading MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53deeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "def load_mnist_data():\n",
    "    \"\"\"\n",
    "    Load MNIST dataset using torchvision\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define transform to convert PIL Image to tensor and normalize\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n",
    "    ])\n",
    "    \n",
    "    # Download and load training data\n",
    "    train_dataset = datasets.MNIST(\n",
    "        root='./Dataset', \n",
    "        train=True, \n",
    "        download=True, \n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    # Download and load test data\n",
    "    test_dataset = datasets.MNIST(\n",
    "        root='./Dataset', \n",
    "        train=False, \n",
    "        download=True, \n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    print(f\"MNIST dataset loaded:\")\n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Test samples: {len(test_dataset)}\")\n",
    "    print(f\"Image shape: {train_dataset[0][0].shape}\")\n",
    "    print(f\"Number of classes: {len(train_dataset.classes)}\")\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "# Load the datasets\n",
    "train_data, test_data = load_mnist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711b53d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTAutoencoderDataset(Dataset):\n",
    "    def __init__(self, mnist_dataset):\n",
    "        self.mnist_dataset = mnist_dataset\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.mnist_dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.mnist_dataset[idx]\n",
    "        # Convert from tensor to numpy and flatten\n",
    "        x = image.numpy().flatten().astype(np.float32)\n",
    "        # Normalize to [0, 1] range (from [-1, 1])\n",
    "        x = (x + 1.0) / 2.0\n",
    "        return torch.tensor(x), torch.tensor(x)  # For autoencoder, input and target are the same\n",
    "\n",
    "train_dataset = MNISTAutoencoderDataset(train_data)\n",
    "test_dataset = MNISTAutoencoderDataset(test_data)\n",
    "\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Test set size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cd5ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MLPA_on_MNIST(dataset):\n",
    "    \n",
    "    # Define autoencoder architecture\n",
    "    input_dim = 784  # 28x28 images flattened\n",
    "    encoder_hidden_dims = [128]\n",
    "    latent_dim = 64\n",
    "    \n",
    "    # Create autoencoder model\n",
    "    autoencoder = MLPAutoencoder(input_dim, encoder_hidden_dims, latent_dim, \n",
    "                                 None, activation_fn=ReLU, learning_rate=0.001)\n",
    "    \n",
    "    # Train the autoencoder\n",
    "    history = train_model(autoencoder.model, dataset, epochs=100, batch_size=64, \n",
    "                          grad_accumulation_steps=1, patience=10, relative_loss_threshold=0.01)\n",
    "\n",
    "    return autoencoder, history\n",
    "\n",
    "def visualize_reconstructions(dataset, model, img_shape=(28, 28)):\n",
    "        \"\"\"\n",
    "        Visualize original and reconstructed images\n",
    "        \"\"\"\n",
    "        # Select one image from each digit class\n",
    "        num_classes = 10\n",
    "        selected_samples = []\n",
    "        selected_labels = []\n",
    "\n",
    "        # Get one sample from each class\n",
    "        for digit in range(num_classes):\n",
    "            # Find samples of this digit\n",
    "            for i, (data, _) in enumerate(dataset):\n",
    "                # Get the original label from the MNIST dataset\n",
    "                original_label = dataset.mnist_dataset[i][1]\n",
    "                if original_label == digit:\n",
    "                    selected_samples.append(data.numpy())\n",
    "                    selected_labels.append(digit)\n",
    "                    break\n",
    "\n",
    "        # Convert to numpy arrays\n",
    "        selected_samples = np.array(selected_samples)\n",
    "\n",
    "        # Get reconstructions\n",
    "        reconstructions = []\n",
    "        reconstruction_errors = []\n",
    "\n",
    "        for i, sample in enumerate(selected_samples):\n",
    "            # Forward pass through autoencoder\n",
    "            reconstruction = model.predict(sample.reshape(1, -1))\n",
    "            reconstructions.append(reconstruction.flatten())\n",
    "            \n",
    "            # Calculate reconstruction error (MSE)\n",
    "            error = np.mean((sample - reconstruction.flatten()) ** 2)\n",
    "            reconstruction_errors.append(error)\n",
    "\n",
    "        # Plotting\n",
    "        fig, axes = plt.subplots(2, num_classes, figsize=(15, 6))\n",
    "\n",
    "        for i in range(num_classes):\n",
    "            # Original image\n",
    "            original = selected_samples[i].reshape(img_shape)\n",
    "            axes[0, i].imshow(original, cmap='gray')\n",
    "            axes[0, i].set_title(f'Original\\nDigit {selected_labels[i]}')\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            # Reconstructed image\n",
    "            reconstructed = reconstructions[i].reshape(img_shape)\n",
    "            axes[1, i].imshow(reconstructed, cmap='gray')\n",
    "            axes[1, i].set_title(f'Class {selected_labels[i]}\\nError: {reconstruction_errors[i]:.4f}')\n",
    "            axes[1, i].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.suptitle('Original vs Reconstructed Images(sudershan.sarraf)', y=1.02, fontsize=16)\n",
    "        plt.show()\n",
    "\n",
    "        # Print reconstruction errors\n",
    "        print(\"\\nReconstruction Errors by Class:\")\n",
    "        for i, error in enumerate(reconstruction_errors):\n",
    "            print(f\"Class {i}: {error:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423d5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder, history = train_MLPA_on_MNIST(train_dataset)\n",
    "visualize_reconstructions(test_dataset, autoencoder.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7274bc",
   "metadata": {},
   "source": [
    "# Anamoly Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b52e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LFWAnomalyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for LFW anomaly detection\n",
    "    Normal class: George W Bush\n",
    "    Anomalous class: All other people\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lfw_path, normal_class=\"George_W_Bush\", img_size=(250,250), \n",
    "                 max_normal_samples=None, max_anomaly_samples=1000):\n",
    "        \"\"\"\n",
    "        Initialize LFW anomaly detection dataset\n",
    "        \"\"\"\n",
    "        self.lfw_path = lfw_path\n",
    "        self.normal_class = normal_class\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        self.images = []\n",
    "        self.labels = []  # 0 = normal, 1 = anomaly\n",
    "        self.person_names = []\n",
    "        \n",
    "        # Load normal class images (George W Bush)\n",
    "        normal_path = os.path.join(lfw_path, normal_class)\n",
    "        if os.path.exists(normal_path):\n",
    "            normal_files = glob.glob(os.path.join(normal_path, \"*.jpg\"))\n",
    "            if max_normal_samples:\n",
    "                normal_files = normal_files[:max_normal_samples]\n",
    "                \n",
    "            print(f\"Loading {len(normal_files)} normal images from {normal_class}\")\n",
    "            \n",
    "            for img_path in normal_files:\n",
    "                try:\n",
    "                    img = Image.open(img_path).convert('L')\n",
    "                    img = img.resize(self.img_size)\n",
    "                    img_array = np.array(img).astype(np.float32) / 255.0\n",
    "                    self.images.append(img_array)\n",
    "                    self.labels.append(0)  # Normal\n",
    "                    self.person_names.append(normal_class)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {img_path}: {e}\")\n",
    "        \n",
    "        # Load anomalous class images (all other people)\n",
    "        anomaly_count = 0\n",
    "        all_dirs = [d for d in os.listdir(lfw_path) if os.path.isdir(os.path.join(lfw_path, d))]\n",
    "        \n",
    "        print(f\"Loading anomaly images from other people...\")\n",
    "        \n",
    "        for person_dir in all_dirs:\n",
    "            if person_dir == normal_class:\n",
    "                continue\n",
    "                \n",
    "            person_path = os.path.join(lfw_path, person_dir)\n",
    "            person_files = glob.glob(os.path.join(person_path, \"*.jpg\"))\n",
    "            \n",
    "            for img_path in person_files:\n",
    "                if max_anomaly_samples and anomaly_count >= max_anomaly_samples:\n",
    "                    break\n",
    "                    \n",
    "                try:\n",
    "                    img = Image.open(img_path).convert('L')\n",
    "                    img = img.resize(self.img_size)\n",
    "                    img_array = np.array(img).astype(np.float32) / 255.0\n",
    "                    self.images.append(img_array)\n",
    "                    self.labels.append(1)  # Anomaly\n",
    "                    self.person_names.append(person_dir)\n",
    "                    anomaly_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {img_path}: {e}\")\n",
    "            \n",
    "            if max_anomaly_samples and anomaly_count >= max_anomaly_samples:\n",
    "                break\n",
    "        \n",
    "        print(f\"Dataset loaded: {len([l for l in self.labels if l == 0])} normal, \"\n",
    "              f\"{len([l for l in self.labels if l == 1])} anomaly images\")\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        self.images = np.array(self.images)\n",
    "        self.labels = np.array(self.labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Flatten image for autoencoder\n",
    "        image_flat = image.flatten()\n",
    "        \n",
    "        return torch.FloatTensor(image_flat), torch.FloatTensor([label])\n",
    "    \n",
    "    def get_normal_only(self):\n",
    "        \"\"\"Return dataset with only normal samples for training\"\"\"\n",
    "        normal_indices = np.where(self.labels == 0)[0]\n",
    "        normal_images = self.images[normal_indices]\n",
    "        \n",
    "        class NormalOnlyDataset(Dataset):\n",
    "            def __init__(self, images):\n",
    "                self.images = images\n",
    "            \n",
    "            def __len__(self):\n",
    "                return len(self.images)\n",
    "            \n",
    "            def __getitem__(self, idx):\n",
    "                image = self.images[idx]\n",
    "                image_flat = image.flatten()\n",
    "                return torch.FloatTensor(image_flat), torch.FloatTensor(image_flat)\n",
    "        \n",
    "        return NormalOnlyDataset(normal_images)\n",
    "\n",
    "# Load LFW dataset for anomaly detection\n",
    "lfw_dataset_path = \"Data/Q3/LFW_Dataset\"\n",
    "\n",
    "# Create the full dataset (normal + anomaly for evaluation)\n",
    "full_dataset = LFWAnomalyDataset(\n",
    "    lfw_path=lfw_dataset_path,\n",
    "    normal_class=\"George_W_Bush\",\n",
    "    img_size=(250,250)\n",
    ")\n",
    "\n",
    "# Create training dataset (only normal samples)\n",
    "train_dataset = full_dataset.get_normal_only()\n",
    "\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Full evaluation dataset size: {len(full_dataset)}\")\n",
    "print(f\"Image dimensions: {250*250} (flattened GreyScale)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae923fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_anomaly_autoencoder(train_dataset, latent_dim, img_size=(250,250)):\n",
    "    \"\"\"\n",
    "    Train autoencoder on normal data only for anomaly detection\n",
    "    \"\"\"\n",
    "    # Define autoencoder architecture for face images\n",
    "    input_dim = img_size[0] * img_size[1] * 1  # Grayscale image flattened\n",
    "    encoder_hidden_dims = [4000]\n",
    "    \n",
    "    print(f\"Creating autoencoder for anomaly detection:\")\n",
    "    print(f\"Input dimension: {input_dim}\")\n",
    "    print(f\"Architecture: {input_dim} -> {encoder_hidden_dims} -> {latent_dim}\")\n",
    "    \n",
    "    # Create autoencoder model\n",
    "    autoencoder = MLPAutoencoder(\n",
    "        input_dim=input_dim,\n",
    "        encoder_hidden_dims=encoder_hidden_dims,\n",
    "        latent_dim=latent_dim,\n",
    "        activation_fn=ReLU,\n",
    "        learning_rate=0.0001  # Lower learning rate for face images\n",
    "    )\n",
    "    \n",
    "    # Train the autoencoder on normal data only\n",
    "    print(f\"\\nTraining autoencoder on {len(train_dataset)} normal samples...\")\n",
    "    history = train_model(\n",
    "        autoencoder.model, \n",
    "        train_dataset, \n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        grad_accumulation_steps=1,\n",
    "        patience=10,\n",
    "        relative_loss_threshold=0.01\n",
    "    )\n",
    "    \n",
    "    return autoencoder, history\n",
    "\n",
    "def evaluate_anomaly_detection(autoencoder, eval_dataset, img_size=(250,250)):\n",
    "    \"\"\"\n",
    "    Evaluate anomaly detection performance\n",
    "    \"\"\"\n",
    "    print(\"Evaluating anomaly detection performance...\")\n",
    "    \n",
    "    reconstruction_errors = []\n",
    "    true_labels = []\n",
    "    \n",
    "    # Calculate reconstruction errors for all samples\n",
    "    for i in range(len(eval_dataset)):\n",
    "        image_flat, label = eval_dataset[i]\n",
    "        image_flat = image_flat.numpy().reshape(1, -1)\n",
    "        true_labels.append(int(label.numpy()[0]))\n",
    "        \n",
    "        # Get reconstruction\n",
    "        reconstruction = autoencoder.model.predict(image_flat)\n",
    "        \n",
    "        # Calculate MSE reconstruction error\n",
    "        mse_error = np.mean((image_flat - reconstruction) ** 2)\n",
    "        reconstruction_errors.append(mse_error)\n",
    "        if i%1000 == 0:\n",
    "            print(f\"Evaluated {i+1} Samples...\")\n",
    "    \n",
    "    reconstruction_errors = np.array(reconstruction_errors)\n",
    "    true_labels = np.array(true_labels)\n",
    "    \n",
    "    print(f\"Normal samples reconstruction error: {np.mean(reconstruction_errors[true_labels == 0]):.6f} ± {np.std(reconstruction_errors[true_labels == 0]):.6f}\")\n",
    "    print(f\"Anomaly samples reconstruction error: {np.mean(reconstruction_errors[true_labels == 1]):.6f} ± {np.std(reconstruction_errors[true_labels == 1]):.6f}\")\n",
    "    \n",
    "    # Find optimal threshold using ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(true_labels, reconstruction_errors)\n",
    "    \n",
    "    # Optimal threshold: maximize (TPR - FPR)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    \n",
    "    print(f\"Optimal threshold: {optimal_threshold:.6f}\")\n",
    "    \n",
    "    # Calculate metrics using optimal threshold\n",
    "    predictions = (reconstruction_errors > optimal_threshold).astype(int)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    auc_score = roc_auc_score(true_labels, reconstruction_errors)\n",
    "    precision = precision_score(true_labels, predictions)\n",
    "    recall = recall_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    \n",
    "    print(f\"\\nAnomaly Detection Results:\")\n",
    "    print(f\"AUC Score: {auc_score:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot 1: Reconstruction error distribution\n",
    "    plt.subplot(1, 2, 1)\n",
    "    normal_errors = reconstruction_errors[true_labels == 0]\n",
    "    anomaly_errors = reconstruction_errors[true_labels == 1]\n",
    "    \n",
    "    plt.hist(normal_errors, bins=50, alpha=0.7, label='Normal (George W Bush)', color='blue')\n",
    "    plt.hist(anomaly_errors, bins=50, alpha=0.7, label='Anomaly (Others)', color='red')\n",
    "    plt.axvline(optimal_threshold, color='black', linestyle='--', label=f'Threshold: {optimal_threshold:.4f}')\n",
    "    plt.xlabel('Reconstruction Error (MSE)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Reconstruction Error Distribution(sudershan.sarraf)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: ROC Curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc_score:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
    "    plt.scatter(fpr[optimal_idx], tpr[optimal_idx], color='red', s=100, \n",
    "                label=f'Optimal Point (TPR={tpr[optimal_idx]:.3f}, FPR={fpr[optimal_idx]:.3f})')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve(sudershan.sarraf)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return results\n",
    "    results = {\n",
    "        'auc_score': auc_score,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'optimal_threshold': optimal_threshold,\n",
    "        'reconstruction_errors': reconstruction_errors,\n",
    "        'true_labels': true_labels,\n",
    "        'predictions': predictions,\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr,\n",
    "        'thresholds': thresholds,\n",
    "        'optimal_idx': optimal_idx,\n",
    "        'model': autoencoder\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def visualize_reconstructions_anomaly(autoencoder, eval_dataset, img_size=(250,250), n_samples=10):\n",
    "    \"\"\"\n",
    "    Visualize reconstructions for both normal and anomaly samples\n",
    "    \"\"\"\n",
    "    # Get indices for normal and anomaly samples\n",
    "    normal_indices = []\n",
    "    anomaly_indices = []\n",
    "    \n",
    "    for i in range(len(eval_dataset)):\n",
    "        _, label = eval_dataset[i]\n",
    "        if int(label.numpy()[0]) == 0 and len(normal_indices) < n_samples:\n",
    "            normal_indices.append(i)\n",
    "        elif int(label.numpy()[0]) == 1 and len(anomaly_indices) < n_samples:\n",
    "            anomaly_indices.append(i)\n",
    "        \n",
    "        if len(normal_indices) >= n_samples and len(anomaly_indices) >= n_samples:\n",
    "            break\n",
    "    \n",
    "    # Randomly select indices\n",
    "    normal_indices = random.sample(normal_indices, min(n_samples, len(normal_indices)))\n",
    "    anomaly_indices = random.sample(anomaly_indices, min(n_samples, len(anomaly_indices)))\n",
    "    \n",
    "    fig, axes = plt.subplots(4, n_samples, figsize=(2*n_samples, 8))\n",
    "    \n",
    "    # Plot normal samples\n",
    "    for i, idx in enumerate(normal_indices):\n",
    "        image_flat, _ = eval_dataset[idx]\n",
    "        original = image_flat.numpy().reshape(img_size[0], img_size[1])\n",
    "        \n",
    "        # Get reconstruction\n",
    "        reconstruction = autoencoder.model.predict(image_flat.numpy().reshape(1, -1))\n",
    "        reconstruction = reconstruction.reshape(img_size[0], img_size[1])\n",
    "        \n",
    "        # Calculate reconstruction error\n",
    "        mse_error = np.mean((image_flat.numpy() - reconstruction.flatten()) ** 2)\n",
    "        \n",
    "        # Plot original\n",
    "        axes[0, i].imshow(np.clip(original, 0, 1))\n",
    "        axes[0, i].set_title(f'Normal Original\\nMSE: {mse_error:.4f}', fontsize=8)\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Plot reconstruction\n",
    "        axes[1, i].imshow(np.clip(reconstruction, 0, 1))\n",
    "        axes[1, i].set_title('Normal Recon', fontsize=8)\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    # Plot anomaly samples\n",
    "    for i, idx in enumerate(anomaly_indices):\n",
    "        image_flat, _ = eval_dataset[idx]\n",
    "        original = image_flat.numpy().reshape(img_size[0], img_size[1])\n",
    "        \n",
    "        # Get reconstruction\n",
    "        reconstruction = autoencoder.model.predict(image_flat.numpy().reshape(1, -1))\n",
    "        reconstruction = reconstruction.reshape(img_size[0], img_size[1])\n",
    "        \n",
    "        # Calculate reconstruction error\n",
    "        mse_error = np.mean((image_flat.numpy() - reconstruction.flatten()) ** 2)\n",
    "        \n",
    "        # Plot original\n",
    "        axes[2, i].imshow(np.clip(original, 0, 1))\n",
    "        axes[2, i].set_title(f'Anomaly Original\\nMSE: {mse_error:.4f}', fontsize=8)\n",
    "        axes[2, i].axis('off')\n",
    "        \n",
    "        # Plot reconstruction\n",
    "        axes[3, i].imshow(np.clip(reconstruction, 0, 1))\n",
    "        axes[3, i].set_title('Anomaly Recon', fontsize=8)\n",
    "        axes[3, i].axis('off')\n",
    "    \n",
    "    # Add row labels\n",
    "    axes[0, 0].text(-0.1, 0.5, 'Normal\\nOriginal', transform=axes[0, 0].transAxes, \n",
    "                    rotation=90, va='center', ha='right', fontsize=10, fontweight='bold')\n",
    "    axes[1, 0].text(-0.1, 0.5, 'Normal\\nReconstructed', transform=axes[1, 0].transAxes, \n",
    "                    rotation=90, va='center', ha='right', fontsize=10, fontweight='bold')\n",
    "    axes[2, 0].text(-0.1, 0.5, 'Anomaly\\nOriginal', transform=axes[2, 0].transAxes, \n",
    "                    rotation=90, va='center', ha='right', fontsize=10, fontweight='bold')\n",
    "    axes[3, 0].text(-0.1, 0.5, 'Anomaly\\nReconstructed', transform=axes[3, 0].transAxes, \n",
    "                    rotation=90, va='center', ha='right', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.suptitle('Anomaly Detection: Reconstruction Comparison\\n(sudershan.sarraf)', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156548d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the complete anomaly detection pipeline\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ANOMALY DETECTION ON LFW DATASET\")\n",
    "print(\"=\"*60)\n",
    "print(\"Normal class: George W Bush\")\n",
    "print(\"Anomaly class: All other people\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Step 1: Train autoencoder on normal data only\n",
    "print(\"\\nSTEP 1: Training autoencoder on normal data...\")\n",
    "anomaly_autoencoder, training_history = train_anomaly_autoencoder(\n",
    "    train_dataset,\n",
    "    2000, \n",
    "    img_size=(250,250)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bc6bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Evaluate on full dataset (normal + anomaly)\n",
    "print(\"\\nSTEP 2: Evaluating anomaly detection performance...\")\n",
    "evaluation_results = evaluate_anomaly_detection(\n",
    "    anomaly_autoencoder, \n",
    "    full_dataset, \n",
    "    img_size=(250, 250)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981f19e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Visualize reconstructions for normal and anomaly samples\n",
    "print(\"\\nSTEP 3: Visualizing reconstructions...\")\n",
    "visualize_reconstructions_anomaly(anomaly_autoencoder, full_dataset, img_size=(250,250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1041ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck = [64, 128, 256]\n",
    "results = {}\n",
    "for dim in bottleneck:\n",
    "    print(f\"\\n{'='*20} Testing Bottleneck dimension: {dim} {'='*20}\\\\n\")\n",
    "    \n",
    "    # Train autoencoder\n",
    "    anomaly_autoencoder, training_history = train_anomaly_autoencoder(\n",
    "        train_dataset,\n",
    "        dim, \n",
    "        img_size=(250,250)\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    result = evaluate_anomaly_detection(\n",
    "        anomaly_autoencoder, \n",
    "        full_dataset, \n",
    "        img_size=(250,250)\n",
    "    )\n",
    "    \n",
    "    results[dim] = result\n",
    "\n",
    "for dim, res in results.items():\n",
    "    print(f\"Latent dim {dim}: AUC={res['auc_score']:.4f}, Precision={res['precision']:.4f}, Recall={res['recall']:.4f}, F1={res['f1_score']:.4f}\")\n",
    "\n",
    "    # Plot all ROC curves together\n",
    "plt.figure(figsize=(12, 5))\n",
    "colors = ['blue', 'red', 'green']\n",
    "for i, (dim, res) in enumerate(results.items()):\n",
    "    plt.plot(res['fpr'], res['tpr'], color=colors[i], lw=2, \n",
    "                label=f'Latent dim {dim}')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=1, linestyle='--', label='Random')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves Comparison(sudershan.sarraf)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9aedf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(image_flat, reconstruction, title, img_size=(250,250)):\n",
    "    \"\"\"\n",
    "    Display original and reconstructed images with proper handling of RGB channels\n",
    "    \"\"\"\n",
    "    # Ensure we have the right shape for RGB\n",
    "    original = image_flat.reshape(img_size[0], img_size[1])\n",
    "    reconstructed = reconstruction.reshape(img_size[0], img_size[1])\n",
    "    \n",
    "    # Debug prints to understand the data\n",
    "    print(f\"Original image stats: min={original.min():.4f}, max={original.max():.4f}, mean={original.mean():.4f}\")\n",
    "    print(f\"Reconstructed image stats: min={reconstructed.min():.4f}, max={reconstructed.max():.4f}, mean={reconstructed.mean():.4f}\")\n",
    "    print(f\"Original shape: {original.shape}, Reconstructed shape: {reconstructed.shape}\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(np.clip(original, 0, 1))\n",
    "    plt.title(f'Original Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(np.clip(reconstructed, 0, 1))\n",
    "    plt.title('Reconstructed Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Show the difference\n",
    "    plt.subplot(1, 3, 3)\n",
    "    diff = np.abs(original - reconstructed)\n",
    "    plt.imshow(diff)\n",
    "    plt.title('Absolute Difference')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.suptitle(title, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def comprehensive_visualization(autoencoder, history, eval_dataset, img_size=(250,250)):\n",
    "    optimal_threshold = history['optimal_threshold']\n",
    "    print(f\"Using optimal threshold: {optimal_threshold:.6f}\")\n",
    "    \n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for i in range(len(eval_dataset)):\n",
    "        image_flat, label = eval_dataset[i]\n",
    "        image_flat_np = image_flat.numpy()\n",
    "        true_label = int(label.numpy()[0])\n",
    "        \n",
    "        # Get reconstruction\n",
    "        reconstruction = autoencoder.model.predict(image_flat_np.reshape(1, -1))\n",
    "        # Calculate MSE reconstruction error\n",
    "        mse_error = np.mean((image_flat_np - reconstruction.flatten()) ** 2)\n",
    "        prediction = int(mse_error > optimal_threshold)\n",
    "        image_flat=image_flat_np\n",
    "        \n",
    "        if prediction == true_label:\n",
    "                if true_label == 0 and tn == 0:\n",
    "                    display_images(image_flat, reconstruction, title=f'True Negative - Reconstruction error: {mse_error:.6f}(sudershan.sarraf)', img_size=img_size)\n",
    "                    tn = 1\n",
    "                elif true_label == 1 and tp == 0:\n",
    "                    display_images(image_flat, reconstruction, title=f'True Positive - Reconstruction error: {mse_error:.6f}(sudershan.sarraf)', img_size=img_size)\n",
    "                    tp = 1\n",
    "        else:\n",
    "            if prediction == 1 and fp == 0:\n",
    "                display_images(image_flat, reconstruction, title=f'False Positive - Reconstruction error: {mse_error:.6f}(sudershan.sarraf)', img_size=img_size)\n",
    "                fp = 1\n",
    "            elif prediction == 0 and fn == 0:\n",
    "                display_images(image_flat, reconstruction, title=f'False Negative - Reconstruction error: {mse_error:.6f}(sudershan.sarraf)', img_size=img_size)\n",
    "                fn = 1\n",
    "        if tp and tn and fp and fn:\n",
    "            break\n",
    "    \n",
    "    # Plot precision-recall curve\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    thresholds_pr = []\n",
    "\n",
    "    reconstruction_errors = history['reconstruction_errors']\n",
    "    true_labels = history['true_labels']\n",
    "\n",
    "    # Calculate precision-recall for different thresholds\n",
    "    threshold_range = np.linspace(reconstruction_errors.min(), reconstruction_errors.max(), 1000)\n",
    "\n",
    "    for threshold in threshold_range:\n",
    "        predictions = (reconstruction_errors > threshold).astype(int)\n",
    "        if np.sum(predictions) > 0:  # Avoid division by zero\n",
    "            precision = precision_score(true_labels, predictions, zero_division=0)\n",
    "            recall = recall_score(true_labels, predictions, zero_division=0)\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            thresholds_pr.append(threshold)\n",
    "\n",
    "    # Plot precision-recall curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recalls, precisions, color='blue', lw=2, label='Precision-Recall curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve(sudershan.sarraf)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.show()\n",
    "\n",
    "comprehensive_visualization(results[128]['model'], results[128], full_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (smai-env)",
   "language": "python",
   "name": "smai-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
